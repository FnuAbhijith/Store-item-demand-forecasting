# ğŸ›ï¸ Store Item Demand Forecasting (End-to-End with AWS Deployment)  

This repository contains an **end-to-end machine learning pipeline** for **store-item demand forecasting**.  
It covers **data preparation, feature engineering, model training, evaluation, and deployment on AWS** (artifact included).  

---

## ğŸ“Œ Project Overview  
- **Data Exploration & Feature Engineering:** Time-based lags, rolling averages, seasonality, holiday flags.  
- **Model Training:** Classical ML (XGBoost, LightGBM, RandomForest) & statistical methods.  
- **Evaluation:** RMSE / MAE with backtesting via sliding windows.  
- **Deployment:** Packaged model (`artifacts/model.tar.gz`) for AWS SageMaker / EC2 deployment.  

---

## ğŸ“‚ Repository Structure  
```
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Store_Item_Demand_Forecast.ipynb    # Main notebook (EDA â†’ Features â†’ Modeling â†’ Evaluation)
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ model.tar.gz                        # Trained model artifact (ready for AWS deployment)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ local_infer.py                      # Local inference helper (load artifact, test predictions)
â”‚   â””â”€â”€ deploy_sagemaker_template.py        # Minimal SageMaker deployment template
â”œâ”€â”€ data/
â”‚   â””â”€â”€ .gitkeep                            # Placeholder (datasets ignored in Git)
â”œâ”€â”€ requirements.txt                        # Dependencies
â”œâ”€â”€ .gitignore                              # Ignore unnecessary files & large data
â””â”€â”€ README.md                               # Documentation
```

---

## âš™ï¸ Setup & Installation  
1. Clone the repository:  
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
```

2. Create & activate environment:  
```bash
conda create -n store-forecast python=3.11 -y
conda activate store-forecast
```

3. Install dependencies:  
```bash
pip install -r requirements.txt
```

4. Run the notebook:  
```bash
jupyter notebook notebooks/Store_Item_Demand_Forecast.ipynb
```

---

## ğŸ“Š Datasets  
Expected layout in `data/` (ignored in GitHub):  
```
data/
  â”œâ”€â”€ train.csv
  â”œâ”€â”€ test.csv
  â””â”€â”€ items.csv
```

---

## ğŸš€ AWS Deployment  

### âœ… Using SageMaker  
- Upload `artifacts/model.tar.gz` to S3  
- Use `scripts/deploy_sagemaker_template.py` to create SageMaker Model & Endpoint  
- Endpoint serves real-time predictions  

### âœ… Using EC2  
- Copy `model.tar.gz` to EC2 instance  
- Unpack & serve with **Flask/FastAPI** inference script  

---

## ğŸ“ˆ Results  
- Models benchmarked: XGBoost, LightGBM, RandomForest, Linear Regression  
- Evaluation: RMSE & MAE across backtesting windows  
- Insights: seasonality & store-level variation captured by engineered features  

---

## ğŸ”‘ Key Highlights  
- **Time-series demand forecasting** with engineered features  
- **Multiple models tested** with evaluation metrics  
- **Deployment-ready artifact** for AWS SageMaker/EC2  
- **End-to-end pipeline**: data â†’ model â†’ evaluation â†’ deployment  

---

## ğŸ‘¤ Author  
**Abhijith Shetty**  
ğŸ“ Masterâ€™s Student in Data Science, University of Memphis  
ğŸ’¼ Aspiring Data Scientist / ML Engineer  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/fnuabhijith) | [GitHub](https://github.com/FnuAbhijith) | [Portfolio](https://fnuabhijith.github.io/Abhijith-Portfolio)  

---

âœ¨ *This project showcases applied forecasting, ML model building, and deployment â€” a complete workflow relevant for Data Scientist / ML Engineer roles.*  
